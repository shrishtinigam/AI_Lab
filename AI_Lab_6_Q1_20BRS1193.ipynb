{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1648198475726,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "s-76LueFYykJ",
    "outputId": "fdee7e20-1601-435a-86a5-44df2261e71d",
    "scrolled": true
   },
   "source": [
    "# AI Lab 6 Q1 Meher Shrishti Nigam 20BRS1193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648198477785,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "GpjIc2dccZAR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Quick value count calculator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1648198513265,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "_tZGP0k2c8ba"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('tennis2.csv',  names=['outlook','temp','humidity','wind','play'])\n",
    "dataset=dataset.drop('day',axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648193809050,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "gNZdkDvEbx4U",
    "outputId": "5406f70b-9e2b-4358-a1f0-f9e6ae5d57ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temp humidity    wind play\n",
       "D1     Sunny   Hot     High    Weak   No\n",
       "D2     Sunny   Hot     High  Strong   No\n",
       "D3  Overcast   Hot     High    Weak  Yes\n",
       "D4      Rain  Mild     High    Weak  Yes\n",
       "D5      Rain  Cool   Normal    Weak  Yes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1648193983968,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "DBLCBS-Gb4lH"
   },
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: # for each class in the label\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset        \n",
    "    print(\"Entropy before splitting \")\n",
    "    print(total_entr)\n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1648193999946,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "BdYIMtHUcRZA"
   },
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1648194002862,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "qY340mMmcbhc"
   },
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list: #all possible values of a feature\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1648194009116,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "Q-D9RsBkcrCP"
   },
   "outputs": [],
   "source": [
    "#find feature with hightest information gain\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label) # feature names in the dataset\n",
    "                                            \n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:  \n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain: \n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648194014210,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "TMOsFc_pcnyD"
   },
   "outputs": [],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of feature_value = count of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #should extend the node, so the branch is marked with ?\n",
    "            \n",
    "    return tree, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1648194019375,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "Hx8hlEsBc6gJ"
   },
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes empty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1648194024345,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "xGD8m-bgdGMB"
   },
   "outputs": [],
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data_m, label, class_list) #start calling recursion\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648194027520,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "BNxtoo9_dHJs",
    "outputId": "ea654b1b-c81e-43cf-b4a6-cbd42a267ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy before splitting \n",
      "0.9402859586706311\n",
      "Entropy before splitting \n",
      "0.9402859586706311\n",
      "Entropy before splitting \n",
      "0.9402859586706311\n",
      "Entropy before splitting \n",
      "0.9402859586706311\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n",
      "Entropy before splitting \n",
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "tree = id3(dataset, 'play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1648194058211,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "H7VS98c1lLCs"
   },
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1648194060692,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "NQeJ4VYzlNHK"
   },
   "outputs": [],
   "source": [
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_preditct += 1 \n",
    "        else:\n",
    "            wrong_preditct += 1 \n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1648194065683,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "BAH0BB4tmxhC",
    "outputId": "4291ff04-4128-41eb-88c4-e27caa8ab332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"tennis_test.csv\")\n",
    "accuracy = evaluate(tree, test_dataset, 'play') # evaluating the test dataset\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree using sklearn -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1472,
     "status": "ok",
     "timestamp": 1648194135275,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "ar-CGuljBZ2P"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1648194997635,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "JEXFcxCsBvBE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      outlook  temp humidity    wind play\n",
      "D1      Sunny   Hot     High    Weak   No\n",
      "D2      Sunny   Hot     High  Strong   No\n",
      "D3   Overcast   Hot     High    Weak  Yes\n",
      "D4       Rain  Mild     High    Weak  Yes\n",
      "D5       Rain  Cool   Normal    Weak  Yes\n",
      "D6       Rain  Cool   Normal  Strong   No\n",
      "D7   Overcast  Cool   Normal  Strong  Yes\n",
      "D8      Sunny  Mild     High    Weak   No\n",
      "D9      Sunny  Cool   Normal    Weak  Yes\n",
      "D10      Rain  Mild   Normal    Weak  Yes\n",
      "D11     Sunny  Mild   Normal  Strong  Yes\n",
      "D12  Overcast  Mild     High  Strong  Yes\n",
      "D13  Overcast   Hot   Normal    Weak  Yes\n",
      "D14      Rain  Mild     High  Strong   No\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "col_names=['outlook','temp','humidity','wind','play']\n",
    "dt = pd.read_csv(\"tennis.csv\", header=None, names=col_names)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1648194656108,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "iaCC_yM9DfN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.22.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\meher\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing - to deal with categorical nominal data \n",
    "!pip install scikit-learn\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['outlook','temp','humidity','wind']\n",
    "X = dt[feature_cols] # Features\n",
    "y = dt.play # Target variable\n",
    "\n",
    "# Using OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "feature_array = ohe.fit_transform(dt[['outlook','temp','humidity','wind']])\n",
    "print(feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Overcast', 'Rain', 'Sunny'], dtype=object), array(['Cool', 'Hot', 'Mild'], dtype=object), array(['High', 'Normal'], dtype=object), array(['Strong', 'Weak'], dtype=object)]\n",
      "\n",
      "\n",
      "[array(['Overcast', 'Rain', 'Sunny'], dtype=object)\n",
      " array(['Cool', 'Hot', 'Mild'], dtype=object)\n",
      " array(['High', 'Normal'], dtype=object)\n",
      " array(['Strong', 'Weak'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Getting the labels\n",
    "feature_labels = ohe.categories_\n",
    "print(feature_labels)\n",
    "print(\"\\n\")\n",
    "feature_labels = np.array(feature_labels,dtype=object).ravel()\n",
    "print(feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Overcast', 'Rain', 'Sunny','Cool', 'Hot', 'Mild','High', 'Normal','Strong', 'Weak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Overcast  Rain  Sunny  Cool  Hot  Mild  High  Normal  Strong  Weak\n",
      "0        0.0   0.0    1.0   0.0  1.0   0.0   1.0     0.0     0.0   1.0\n",
      "1        0.0   0.0    1.0   0.0  1.0   0.0   1.0     0.0     1.0   0.0\n",
      "2        1.0   0.0    0.0   0.0  1.0   0.0   1.0     0.0     0.0   1.0\n",
      "3        0.0   1.0    0.0   0.0  0.0   1.0   1.0     0.0     0.0   1.0\n",
      "4        0.0   1.0    0.0   1.0  0.0   0.0   0.0     1.0     0.0   1.0\n",
      "5        0.0   1.0    0.0   1.0  0.0   0.0   0.0     1.0     1.0   0.0\n",
      "6        1.0   0.0    0.0   1.0  0.0   0.0   0.0     1.0     1.0   0.0\n",
      "7        0.0   0.0    1.0   0.0  0.0   1.0   1.0     0.0     0.0   1.0\n",
      "8        0.0   0.0    1.0   1.0  0.0   0.0   0.0     1.0     0.0   1.0\n",
      "9        0.0   1.0    0.0   0.0  0.0   1.0   0.0     1.0     0.0   1.0\n",
      "10       0.0   0.0    1.0   0.0  0.0   1.0   0.0     1.0     1.0   0.0\n",
      "11       1.0   0.0    0.0   0.0  0.0   1.0   1.0     0.0     1.0   0.0\n",
      "12       1.0   0.0    0.0   0.0  1.0   0.0   0.0     1.0     0.0   1.0\n",
      "13       0.0   1.0    0.0   0.0  0.0   1.0   1.0     0.0     1.0   0.0\n"
     ]
    }
   ],
   "source": [
    "# Creating final dataframe\n",
    "dt2 = pd.DataFrame(feature_array, columns = cols)\n",
    "print(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1648194907250,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "7onp2eDaDqnB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dt2, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1648194908884,
     "user": {
      "displayName": "jothi ramasamy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgyaUtCfOJTjGdQNbNaMQePrJ_KxPbPFf2SbSO1ug=s64",
      "userId": "05600303898970236765"
     },
     "user_tz": -330
    },
    "id": "FHTTGQ-hD7EE",
    "outputId": "1956d9d9-2cbb-4eee-975e-168d739a8820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'Yes' 'No']\n",
      "D10    Yes\n",
      "D12    Yes\n",
      "D1      No\n",
      "Name: play, dtype: object\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(X, y)\n",
    "model_dec = DecisionTreeClassifier(max_depth = 3, random_state = 42, criterion = 'entropy')\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model_dec = model_dec.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model_dec.predict(x_test)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "accuracy=model_dec.score(x_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our accuracy is 100%. y_pred and y_test are also the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_0 <= 0.50\n",
      "|   |--- feature_7 <= 0.50\n",
      "|   |   |--- feature_1 <= 0.50\n",
      "|   |   |   |--- class: No\n",
      "|   |   |--- feature_1 >  0.50\n",
      "|   |   |   |--- class: No\n",
      "|   |--- feature_7 >  0.50\n",
      "|   |   |--- feature_8 <= 0.50\n",
      "|   |   |   |--- class: Yes\n",
      "|   |   |--- feature_8 >  0.50\n",
      "|   |   |   |--- class: No\n",
      "|--- feature_0 >  0.50\n",
      "|   |--- class: Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "text_representation = export_text(model_dec)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNv6wTBkg7jIA4c88XXT85q",
   "name": "DTreeentropy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
